#!/usr/bin/env bash
#
# ç¼–æ’å¼MRå®¡æŸ¥è„šæœ¬
# æ”¯æŒå¤§è§„æ¨¡MRçš„æ™ºèƒ½æ‹†åˆ†å’Œå¹¶è¡Œå®¡æŸ¥
#
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
# shellcheck source=scripts/common.sh
source "${SCRIPT_DIR}/common.sh"
# shellcheck source=scripts/load_prompt.sh
source "${SCRIPT_DIR}/load_prompt.sh"

cd "${REPO_ROOT}"

require_env GITLAB_TOKEN
require_env TARGET_REPO_URL
require_env TARGET_BRANCH
require_env SOURCE_BRANCH
require_env TARGET_MR_IID
require_env MR_TITLE
require_env MR_DESCRIPTION

echo "=========================================="
echo "  ğŸ¤– Orchestrated MR Code Review"
echo "========================================="
echo "[INFO] MR #${TARGET_MR_IID}: ${MR_TITLE}"
echo "[INFO] ${SOURCE_BRANCH} â†’ ${TARGET_BRANCH}"
echo ""

# å‘å¸ƒå¼€å§‹å®¡æŸ¥çš„è¯„è®º
echo "[INFO] Posting acknowledgment to MR..."
NOTE_BODY=$(load_prompt "review_ack")

if [ -n "${CI_PIPELINE_URL:-}" ]; then
  NOTE_BODY="${NOTE_BODY}

---
- [ğŸ”— Review Session](${CI_PIPELINE_URL})"
fi

API="${UPSTREAM_GITLAB_BASE_URL}/api/v4/projects/${TARGET_PROJECT_ID}"

curl --fail --silent --show-error \
  --request POST \
  --header "PRIVATE-TOKEN: ${GITLAB_TOKEN}" \
  --data-urlencode "body=${NOTE_BODY}" \
  "${API}/merge_requests/${TARGET_MR_IID}/notes" > /dev/null || {
  echo "[WARN] Failed to post acknowledgment"
}

# å…‹éš†ä»“åº“
echo "[INFO] Cloning repository..."
python3 <<'PY' > authed_repo_url.txt
import os
from urllib.parse import quote, urlparse, urlunparse

token = os.environ["GITLAB_TOKEN"]
repo = os.environ["TARGET_REPO_URL"]
parsed = urlparse(repo)
netloc = f"oauth2:{quote(token, safe='')}@{parsed.netloc}"
authed = urlunparse((parsed.scheme, netloc, parsed.path, parsed.params, parsed.query, parsed.fragment))
print(authed)
PY

AUTHED_URL="$(cat authed_repo_url.txt)"

# ä½¿ç”¨ç¯å¢ƒå˜é‡æŒ‡å®šçš„ç›®å½•åï¼ˆé»˜è®¤ repo-bï¼‰
REPO_DIR="${REPO_DIR:-repo-b}"
echo "[INFO] Using repository directory: ${REPO_DIR}"

# æ£€æŸ¥æ˜¯å¦å·²æœ‰é¢„å…‹éš†çš„ä»“åº“ï¼ˆæ¥è‡ªé¡¹ç›®ç†è§£é¢„åˆ†æï¼‰
if [ -d "${REPO_DIR}" ] && [ "${SKIP_REPO_CLONE}" = "true" ]; then
  echo "[INFO] Using existing ${REPO_DIR} directory (project understanding enabled)"
else
  rm -rf "${REPO_DIR}"
  GIT_TERMINAL_PROMPT=0 git clone "${AUTHED_URL}" "${REPO_DIR}" >/dev/null 2>&1 || {
    echo "[ERROR] Failed to clone repository" >&2
    exit 1
  }
fi

cd "${REPO_DIR}"

echo "[INFO] Fetching branches..."
git fetch origin "${SOURCE_BRANCH}" "${TARGET_BRANCH}" >/dev/null 2>&1 || {
  echo "[ERROR] Failed to fetch branches" >&2
  exit 1
}

# æ£€å‡ºæºåˆ†æ”¯
git checkout "${SOURCE_BRANCH}" >/dev/null 2>&1 || {
  echo "[ERROR] Failed to checkout ${SOURCE_BRANCH}" >&2
  exit 1
}

# ==========================================
# åŠ è½½é¡¹ç›®ç†è§£ä¸Šä¸‹æ–‡
# ==========================================
echo ""
echo "=== Loading Project Context ==="
echo ""

cd "${REPO_ROOT}"

PROJECT_CONTEXT_FILE=""

if [ "${ENABLE_PROJECT_UNDERSTANDING:-true}" = "true" ]; then
  echo "[INFO] Loading project understanding context..."
  
  # è®¾ç½®ä¸Šä¸‹æ–‡ç®¡ç†å™¨éœ€è¦çš„å˜é‡
  export PROJECT_ID="${TARGET_PROJECT_ID}"
  export BRANCH="${SOURCE_BRANCH}"
  export CI_COMMIT_SHA=$(cd "${REPO_DIR}" && git rev-parse HEAD)
  export CI_COMMIT_BEFORE_SHA=$(cd "${REPO_DIR}" && git rev-parse HEAD~1 2>/dev/null || echo "${CI_COMMIT_SHA}")
  export CURRENT_COMMIT="${CI_COMMIT_SHA}"
  export PARENT_COMMIT="${CI_COMMIT_BEFORE_SHA}"
  export AZURE_CONNECTION="${AZURE_STORAGE_CONNECTION_STRING:-}"
  
  if [ -n "${AZURE_CONNECTION}" ]; then
    echo "[INFO] Running CI Context Manager..."
    if bash scripts/ci_context_manager.sh 2>&1 | tee context_manager.log; then
      if [ -f "${REPO_DIR}/.copilot/project_context.md" ]; then
        PROJECT_CONTEXT_FILE="${REPO_DIR}/.copilot/project_context.md"
        echo "[INFO] âœ“ Project context loaded from cache"
      fi
    else
      echo "[WARN] Context manager had issues, continuing without cached context"
    fi
  fi
  
  # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œè¿è¡Œå®Œæ•´åˆ†æ
  if [ -z "${PROJECT_CONTEXT_FILE}" ]; then
    echo "[INFO] Running project analysis..."
    export PYTHONPATH="${PWD}/index_repo/src:${PYTHONPATH:-}"
    
    if python3 -m project_understanding.cli \
        "${REPO_DIR}" \
        --output-dir ".copilot" \
        --output-file project_context.md \
        --no-cache \
        --timeout 1800 \
        -v 2>&1 | tee project_analysis.log; then
      
      if [ -f "${REPO_DIR}/.copilot/project_context.md" ]; then
        PROJECT_CONTEXT_FILE="${REPO_DIR}/.copilot/project_context.md"
        echo "[INFO] âœ“ Project analysis completed"
      fi
    else
      echo "[WARN] Project analysis failed, continuing without context"
    fi
  fi
else
  echo "[INFO] Project understanding disabled"
fi

if [ -n "${PROJECT_CONTEXT_FILE}" ]; then
  echo "[INFO] Project context available at ${PROJECT_CONTEXT_FILE}"
  echo "[INFO] Context size: $(wc -c < "${PROJECT_CONTEXT_FILE}") bytes"
fi

cd "${REPO_DIR}"

echo ""
echo "[INFO] On branch: $(git branch --show-current)"
git fetch origin "${SOURCE_BRANCH}" "${TARGET_BRANCH}" >/dev/null 2>&1 || {
  echo "[ERROR] Failed to fetch branches" >&2
  exit 1
}

# æ£€å‡ºæºåˆ†æ”¯
git checkout "${SOURCE_BRANCH}" >/dev/null 2>&1 || {
  echo "[ERROR] Failed to checkout ${SOURCE_BRANCH}" >&2
  exit 1
}

# ==========================================
# ç¬¬ä¸€é˜¶æ®µï¼šç”Ÿæˆä»»åŠ¡è®¡åˆ’
# ==========================================
echo ""
echo "=== Phase 1: Generating Task Plan ==="
echo ""

python3 "${SCRIPT_DIR}/mr_review_planner.py" \
  --mr-iid "${TARGET_MR_IID}" \
  --mr-title "${MR_TITLE}" \
  --base-branch "origin/${TARGET_BRANCH}" \
  --head-branch "origin/${SOURCE_BRANCH}" \
  --mr-description "${MR_DESCRIPTION}" \
  --output task_plan.json || {
  echo "[ERROR] Failed to generate task plan" >&2
  exit 1
}

if [ ! -f task_plan.json ]; then
  echo "[ERROR] task_plan.json not found" >&2
  exit 1
fi

echo "[INFO] Task plan generated successfully"
echo "[DEBUG] Task plan contents:"
cat task_plan.json | head -50

# æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡éœ€è¦æ‰§è¡Œ
SUBTASK_COUNT=$(python3 -c "import json; print(len(json.load(open('task_plan.json'))['subtasks']))")
echo "[INFO] Total subtasks to execute: ${SUBTASK_COUNT}"

if [ "$SUBTASK_COUNT" -eq 0 ]; then
  echo "[WARN] No review tasks generated. Exiting."
  
  NO_TASK_BODY="## ğŸ¤– ä»£ç å®¡æŸ¥ç»“æœ

æœªç”Ÿæˆå®¡æŸ¥ä»»åŠ¡ã€‚å¯èƒ½åŸå› ï¼š
- æ‰€æœ‰å˜æ›´éƒ½åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼ˆå¦‚ node_modules, vendor ç­‰ï¼‰
- å˜æ›´æ–‡ä»¶ä¸ºç©º

**MRä¿¡æ¯**ï¼š
- æºåˆ†æ”¯ï¼š${SOURCE_BRANCH}
- ç›®æ ‡åˆ†æ”¯ï¼š${TARGET_BRANCH}
"
  
  curl --silent --show-error --fail \
    --request POST \
    --header "PRIVATE-TOKEN: ${GITLAB_TOKEN}" \
    --data-urlencode "body=${NO_TASK_BODY}" \
    "${API}/merge_requests/${TARGET_MR_IID}/notes" > /dev/null || true
  
  exit 0
fi

# ==========================================
# ç¬¬äºŒé˜¶æ®µï¼šæ‰§è¡Œä»»åŠ¡
# ==========================================
echo ""
echo "=== Phase 2: Executing Review Tasks ==="
echo ""

python3 "${SCRIPT_DIR}/mr_review_executor.py" \
  --plan task_plan.json \
  --workspace "$(pwd)" \
  --output review_results.json \
  --summary-output review_summary.md || {
  
  EXIT_CODE=$?
  echo "[ERROR] Task execution failed with code ${EXIT_CODE}" >&2
  
  # å³ä½¿å¤±è´¥ä¹Ÿå°è¯•å‘å¸ƒéƒ¨åˆ†ç»“æœ
  if [ -f review_summary.md ]; then
    echo "[INFO] Posting partial results..."
    
    PARTIAL_BODY="## âš ï¸ ä»£ç å®¡æŸ¥éƒ¨åˆ†å¤±è´¥

å®¡æŸ¥è¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯ï¼Œä»¥ä¸‹æ˜¯éƒ¨åˆ†ç»“æœï¼š

$(cat review_summary.md)

---
è¯·æ£€æŸ¥ CI/CD æ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚
"
    
    curl --silent --show-error --fail \
      --request POST \
      --header "PRIVATE-TOKEN: ${GITLAB_TOKEN}" \
      --data-urlencode "body=${PARTIAL_BODY}" \
      "${API}/merge_requests/${TARGET_MR_IID}/notes" > /dev/null || true
  fi
  
  exit $EXIT_CODE
}

echo "[INFO] Review execution completed successfully"

# ==========================================
# ç¬¬ä¸‰é˜¶æ®µï¼šå‘å¸ƒç»“æœ
# ==========================================
echo ""
echo "=== Phase 3: Publishing Results ==="
echo ""

if [ ! -f review_summary.md ]; then
  echo "[ERROR] review_summary.md not found" >&2
  exit 1
fi

echo "[INFO] Posting review summary to MR..."

# åªå‘å¸ƒç»Ÿè®¡ä¿¡æ¯ï¼Œä¸åŒ…å«è¯¦ç»†findingsï¼ˆå·²é€šè¿‡inline commentså‘å¸ƒï¼‰
REVIEW_STATS=$(python3 <<'PYSTAT'
import json
from pathlib import Path

results = json.loads(Path('review_results.json').read_text())
review_data = results.get('results_by_type', {}).get('review', {})

stats = review_data.get('statistics', {})
print(f"""### ğŸ“Š å®¡æŸ¥ç»Ÿè®¡

**æ€»ä½“å»ºè®®**: **{review_data.get('recommendation', 'NEEDS_DISCUSSION')}**

**å‘ç°çš„é—®é¢˜**:
- ğŸ”´ Critical: {stats.get('critical', 0)}
- ğŸŸ  Major: {stats.get('major', 0)}
- ğŸŸ¡ Minor: {stats.get('minor', 0)}
- ğŸ’¡ Suggestions: {stats.get('suggestion', 0)}

**å®¡æŸ¥è¦†ç›–**:
- ğŸ“ å®¡æŸ¥æ–‡ä»¶æ•°: {review_data.get('files_reviewed', 0)}
- âœ… å®Œæˆçš„å­ä»»åŠ¡: {review_data.get('subtasks_completed', 0)}
- âŒ å¤±è´¥çš„å­ä»»åŠ¡: {review_data.get('subtasks_failed', 0)}

> ğŸ’¡ è¯¦ç»†çš„å®¡æŸ¥å‘ç°å·²é€šè¿‡å†…è”è¯„è®ºå‘å¸ƒåˆ°ç›¸åº”ä»£ç è¡Œï¼Œæˆ–æŸ¥çœ‹ CI artifacts ä¸­çš„å®Œæ•´æŠ¥å‘Šã€‚
""")
PYSTAT
)

REVIEW_BODY="## ğŸ¤– Copilot ä»£ç å®¡æŸ¥æŠ¥å‘Š

${REVIEW_STATS}"

if [ -n "${CI_PIPELINE_URL:-}" ]; then
  REVIEW_BODY="${REVIEW_BODY}

---
- [ğŸ”— Review Session](${CI_PIPELINE_URL})"
fi

# ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ä»¥ä¾¿å¤„ç†ç‰¹æ®Šå­—ç¬¦
echo "$REVIEW_BODY" > review_comment.txt

curl --silent --show-error --fail \
  --request POST \
  --header "PRIVATE-TOKEN: ${GITLAB_TOKEN}" \
  --data-urlencode "body@review_comment.txt" \
  "${API}/merge_requests/${TARGET_MR_IID}/notes" > /dev/null || {
  echo "[ERROR] Failed to post review comment" >&2
  exit 1
}

echo "[SUCCESS] Review comment posted successfully"

# ==========================================
# ç¬¬å››é˜¶æ®µï¼ˆå¯é€‰ï¼‰ï¼šå‘å¸ƒinline comments
# ==========================================
if [ "${ENABLE_INLINE_REVIEW_COMMENTS:-false}" = "true" ] && [ -f review_results.json ]; then
  echo ""
  echo "=== Phase 4: Posting Inline Comments ==="
  echo ""
  
  # ç”Ÿæˆå®Œæ•´çš„diffæ–‡ä»¶ï¼ˆç”¨äºæå–ä»£ç ä¸Šä¸‹æ–‡ï¼‰
  git diff "origin/${TARGET_BRANCH}...origin/${SOURCE_BRANCH}" > full_diff.txt
  echo "[INFO] Generated full_diff.txt ($(wc -l < full_diff.txt) lines)"
  
  # è·å–commit SHAså¹¶å¯¼å‡ºç¯å¢ƒå˜é‡ä¾›Pythonä½¿ç”¨
  export BASE_SHA=$(git rev-parse "origin/${TARGET_BRANCH}")
  export HEAD_SHA=$(git rev-parse "origin/${SOURCE_BRANCH}")
  export START_SHA=$(git merge-base "origin/${TARGET_BRANCH}" "origin/${SOURCE_BRANCH}")
  export API="${API}"
  export GITLAB_TOKEN="${GITLAB_TOKEN}"
  export TARGET_MR_IID="${TARGET_MR_IID}"
  
  echo "[DEBUG] BASE_SHA=${BASE_SHA}"
  echo "[DEBUG] HEAD_SHA=${HEAD_SHA}"
  echo "[DEBUG] START_SHA=${START_SHA}"
  
  # ä½¿ç”¨Pythonè„šæœ¬å‘å¸ƒinline comments
  python3 <<'PYSCRIPT'
import json
import os
import sys
import subprocess
from pathlib import Path

# è¯»å–ç»“æœ
results = json.loads(Path('review_results.json').read_text())
all_findings = []

# æå–æ‰€æœ‰findings
for task_type, type_results in results.get('results_by_type', {}).items():
    if 'findings' in type_results:
        all_findings.extend(type_results['findings'])

print(f"[INFO] Found {len(all_findings)} total findings")

# ç¯å¢ƒå˜é‡
api_url = os.environ["API"]
token = os.environ["GITLAB_TOKEN"]
mr_iid = os.environ["TARGET_MR_IID"]
base_sha = os.environ["BASE_SHA"]
start_sha = os.environ["START_SHA"]
head_sha = os.environ["HEAD_SHA"]
lang = os.environ.get("COPILOT_LANGUAGE", "zh")

# è¯»å– diff å†…å®¹ä»¥è·å–ä»£ç ä¸Šä¸‹æ–‡
with open('full_diff.txt', 'r', encoding='utf-8') as f:
    diff_text = f.read()

# ä¸­è‹±æ–‡æ¨¡æ¿
templates = {
    'zh': {
        'severity': {'critical': 'ğŸ”´ **ä¸¥é‡**', 'major': 'ğŸŸ  **é‡è¦**'},
        'issue': 'é—®é¢˜',
        'suggestion': 'å»ºè®®',
        'category': 'åˆ†ç±»',
        'code': 'ç›¸å…³ä»£ç '
    },
    'en': {
        'severity': {'critical': 'ğŸ”´ **CRITICAL**', 'major': 'ğŸŸ  **MAJOR**'},
        'issue': 'Issue',
        'suggestion': 'Suggestion',
        'category': 'Category',
        'code': 'Code Context'
    }
}
t = templates.get(lang, templates['zh'])

# åªå‘å¸ƒcriticalå’Œmajorçš„inline comments
high_priority = [f for f in all_findings if f.get('severity') in ['critical', 'major']]
print(f"[INFO] Total findings: {len(all_findings)}")
print(f"[INFO] Critical: {len([f for f in all_findings if f.get('severity') == 'critical'])}")
print(f"[INFO] Major: {len([f for f in all_findings if f.get('severity') == 'major'])}")
print(f"[INFO] Minor: {len([f for f in all_findings if f.get('severity') == 'minor'])}")
print(f"[INFO] Suggestion: {len([f for f in all_findings if f.get('severity') == 'suggestion'])}")
print(f"[INFO] Posting {len(high_priority)} high-priority inline comments")

posted_count = 0
skipped_no_location = 0
for finding in high_priority[:50]:  # æœ€å¤š50ä¸ªinline comments
    file_path = finding.get('file', '')
    line = finding.get('line', 0)
    
    if not file_path or line <= 0:
        skipped_no_location += 1
        print(f"[DEBUG] Skipped finding (no location): {finding.get('title', '')[:50]}")
        continue
    
    severity = finding.get('severity', 'major')
    severity_label = t['severity'].get(severity, t['severity']['major'])
    
    # æå–ä»£ç ä¸Šä¸‹æ–‡ï¼ˆç›®æ ‡è¡Œå‰å3è¡Œï¼‰
    code_context = finding.get('code_snippet', '')
    if not code_context:
        # å¦‚æœ finding ä¸­æ²¡æœ‰ä»£ç ï¼Œå°è¯•ä» diff ä¸­æå–
        for diff_line in diff_text.split('\n'):
            if f'diff --git a/{file_path}' in diff_line:
                # ç®€å•æç¤ºï¼Œå®é™…åº”è¯¥è§£æ diff æ ¼å¼
                code_context = f"Line {line}"
                break
    
    comment_body = f"""{severity_label}: {finding.get('title', '')}

**{t['issue']}**: {finding.get('description', '')}

**{t['suggestion']}**: {finding.get('suggestion', '')}

```
{code_context}
```

---
_{t['category']}: {finding.get('category', 'general')}_
"""
    
    # æ„å»ºAPIè¯·æ±‚
    discussions_url = f"{api_url}/merge_requests/{mr_iid}/discussions"
    cmd = [
        "curl", "--silent", "--show-error",
        "--request", "POST",
        "--header", f"PRIVATE-TOKEN: {token}",
        "--data-urlencode", f"body={comment_body}",
        "--data-urlencode", f"position[base_sha]={base_sha}",
        "--data-urlencode", f"position[start_sha]={start_sha}",
        "--data-urlencode", f"position[head_sha]={head_sha}",
        "--data-urlencode", "position[position_type]=text",
        "--data-urlencode", f"position[new_path]={file_path}",
        "--data-urlencode", f"position[new_line]={line}",
        discussions_url
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, timeout=30)
        if result.returncode == 0:
            posted_count += 1
            print(f"[INFO] Posted inline comment on {file_path}:{line}")
        else:
            print(f"[WARN] Failed to post on {file_path}:{line} - {result.stderr[:200] if result.stderr else result.stdout[:200]}")
    except Exception as e:
        print(f"[WARN] Error posting inline comment: {e}")

print(f"[INFO] Summary: Posted {posted_count}, Skipped (no location) {skipped_no_location}")
PYSCRIPT
  
  echo "[INFO] Inline comments posted"
fi

cd "${REPO_ROOT}"

echo ""
echo "=========================================="
echo "  âœ… Review Complete!"
echo "=========================================="
echo ""
